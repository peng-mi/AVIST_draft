\section{Related Work}

For visual exploration of big datasets, four questions outline the discussion of related work: 1) which type of data should be visualized, and what is the characteristic; 2) how to store and manage big data; 3) how to compute big data and achieve better performance; 4) how to explore and interact with big data.

\subsection{The Exploration of Multidimensional Datasets}
Large multidimensional datasets are very common and ubiquitous. Most of them are usually behavioral data that are generated by people or machines, which have a natural temporal ordering (streaming data)~\cite{Canny}. Besides the large volume,  high velocity is also an important consideration for analyzing such multidimensional datasets~\cite{IBM2011}. For example, network logs and financial transactions can be generated millions per second. When faced with large volume and high velocity multidimensional datasets, analysts may not know what they are looking for; they will know something is interesting only after they find it. In this setting,  analysts have no idea how to formulate their queries. Thus, the data exploration of large time-series and multidimensional datasets is the key ingredient for knowledge discovery~\cite{harvard}.

The exploration driven system for knowledge discovery becomes a novel requirements in the era of ``Big Data". The data exploration becomes a first class for making sense of large streaming multidimensional datasets. Our paper tackles this problem and provides a solution for building an exploration oriented tool by considering the large volume and high velocity datasets.
%handling big data considering: 1) the volume of data (length of data); 2) the velocity of data (speed of data); 3) the attributes of data (width of data). 

\subsection{Big Data Management}
The data management methods vary based on the size of datasets. If a dataset can fit into the computer memory,  the data layout methods and data structure design should be investigated. When a dataset size is larger than the computer memory capacity, data prefetching and out-of-core techniques need considered~\cite{OFC}. If a dataset is even bigger than the computer disk capacity, the distributed file systems such as HDFS (Hadoop Distributed File System)~\cite{HDFS} can be a choice. 

This paper aims to achieve real-time performance for visual exploration of big data on a commodity desktop. Thus it only considers that datasets can fit into the computer memory. Previous researches, such as  imMens~\cite{2013-immens}, use one million or more data items as a threshold. Thus, this paper follows this definition and gives an upper bound of  big data: the capacity of the computer memory.

To manage big data, especially the multidimensional (tabular) datasets, on computer memory, there are two general ways: row oriented format and column oriented format. Abadi et al.~\cite{Abadi:2008} discussed the differences between these two methods, and pointed out that column format can apply compression techniques to significantly reduce data size and improve query performance. For example, Tableau's TDE is based on column oriented format for managing big data.

Data modeling, sampling and aggregation~\cite{2013-immens} are other ways for handling big data. These methods reduce big data into small size based on data precomputations. However, these kinds of  visual explorations are constrained by precomputation methods, and cannot afford flexibility and low level data details. Our paper emphasizes  visual exploration data fine-grained details by complex filtering and highlighting. Thus, we manage the big multidimensional datasets in row oriented format, and utilizes parallel computing for visual exploration of big data on demand. %Section 3 gives more discussion about it.

\subsection{The GPU Acceleration}

Contrasted with CPUs, graphics processing units (GPUs) have two unique features.

\begin{itemize}
	\item More cores and fine levels of parallelism. GPUs are many-core architecture, which may have thousands of cores.  This feature makes the GPUs  specialized compute-intensive, highly parallel computation. 
	\item Higher memory bandwidths. This means that  GPUs can access data in a fast way (usually more than 100GB/s), or more data in a fixed time period.
	%	\item Weak data cache and flow control. GPUs lack of complexity cache organization and sophisticated branch predication.
\end{itemize}

GPUs are more popular in scientific computing and visualization~\cite{volume}, and several factors have hampered them as general-purpose computing in information visualization and visual analysis fields. Primarily GPUs lack of complexity cache organizations and sophisticated branch predications, which makes the complicated sequential algorithms hard to be parallelized on the GPU platform. In fact,  the development of GPU libraries (e.g., Thrust and cuBLAS) lowers the bar for transforming these algorithms to the GPU platform. Another consideration is slow transfers from CPU to GPU memory, and the limited GPU memory size. However, transfer speeds have improved significantly thanks to PCI-bus improvement, and now the GPU memory capacity is quite good (the latest Nvidia Geforce GTX TITAN Z has 12GB memory).  All these GPU developments make it as a possible solution for handling big data to support exploratory data analysis~\cite{Pawliczek}. 

In fact, GPUs have a deep root in graphics and visualization, and they are good at handling million of pixels. This paper aims to utilize GPUs' fine computing parallelism and high memory bandwidths to support exploratory visual analysis of large multidimensional datasets. Thus, we propose AVIST, which is an animated visualization tool, implemented based on a GPU-centric design for visually exploring big time-series and multidimensional datasets. 

\subsection{Big Data Exploration}
Querying is one of the fundamental interaction techniques for exploring data. Polaris~\cite{polaris} features a visual querying language by integrating analysis and visualization of multidimensional datasets. Analysts can construct sophisticated visualizations by simple drag-and-drop operations. However, Polaris is incapable of managing big data. Tableau, the successor of Polaris, makes a big progress for the big data visualization.  whereas it lacks flexible visual filtering for investigating data details.

Animation is a kind of time multiplexing technique~\cite{Fekete} for visualizing large data items. Moreover, it can effectively reveal temporal patterns by significantly improving graphical perception~\cite{animated}. This paper highlights animation interactions for slicing big data into details. Cross-filtering~\cite{weaver2010} is a method for flexible visually drilling-down into fine-grained relationships for multidimensional datasets. Hence we emphasize cross-filtering and utilize the GPUs to improve performance, to achieve fast, flexible and detailed data exploration. 


